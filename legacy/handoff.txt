Project
- Name: VoiceLogin (SwiftUI, Swift 6)
- Core: VoiceIO layer (RealVoiceIO) for speech in/out:
  - TTS via AVSpeechSynthesizer
  - STT via SFSpeechRecognizer + AVAudioEngine
  - RealVoiceIO is @MainActor
  - Uses VoiceOpGate actor (serialize ops) + BoostQueue actor (short-clip playback)
- Voice customization:
  - TTSConfigurable protocol
  - Voice Picker UI with language filter (“<CurrentLanguageName> | All”), multiple “Active” voices, Favorite star, swipe-to-hide/unhide
  - Instant, interrupting previews (sliders/tap)
- Persistence: Application Support/VoiceIO/voices.json

Owner preferences (rdoggett)
- Provide full file replacements rather than micro-edits.
- Always put all code in code blocks (even small snippets).
- File headers must include date (MM-DD-YYYY), “Generated by GPT-5 (OpenAI) — collaborator: rdoggett”.
- Use simple kid-friendly labels (e.g., “Pitch range”, “Speed range”).
- Dynamic language filter label shows current locale language name (e.g., “English”).
- Allow a “bag” of customized voices (multi-select), plus one favorite.
- Interrupt TTS on every preview; never let previews queue up.
- Keep mock TTS only for SwiftUI previews; in-app gear button opens live picker.
- Solutions should compile cleanly under Swift 6 and be actor-safe.

What’s implemented
- RealVoiceIO(@MainActor) with:
  - single init(config: Config? = nil)
  - speak(_:), speak(_:using:)
  - listen(timeout:inactivity:record:)
  - stopSpeakingNow(), stopAll(), hardReset()
  - boosted playback: prepareBoosted/startPreparedBoosted/playBoosted with off-main wait + timeout
  - RecognitionContext (freeform | name(allowed:) | number) to bias STT
    - Ergonomic overload: VoiceIO.listen(..., context:) -> sets context (safely on MainActor) then calls base listen
- VoicePicker:
  - Master sliders + debounced preview (favorite or random active)
  - Per-voice sliders + interrupting previews with suffix
  - Tap row to play sample “My name is <displayName>…”
  - Swipe-to-hide/unhide, toggle “Show hidden”
  - Language filter shows localized name (current language) | All
  - Cancels prior previews to avoid queue buildup

Testing status and constraints
- Unit tests (Swift 6) need:
  - UnitTestBootstrap.swift in the Unit Test target to set UI_TEST_DISABLE_AUTOSTART=1; keep UI tests without this var.
  - RealVoiceIO created on main actor only: await MainActor.run { RealVoiceIO() }
  - Any boosted playback waits must occur off-main via Task.detached and have a short timeout to avoid QoS warnings.
- UI tests:
  - Use predicate-based waits for “Logged in as <Name>”.
  - Prefer accessibility identifiers (e.g., “PrimaryButton”).

Known issues to fix (as of last session)
1) macOS Unit Test QoS warning:
   - testQueueTwoSFXThenTTSHandoff and testPlayBoostedConvenience can still log:
     [Internal] Thread at User-interactive QoS waiting on Default QoS. This is cosmetic if waits are off-main with timeouts; do not block the UI thread.
   - Keep boostedWaitTimeoutSeconds small (e.g., 2.0) in tests.

2) UI tests failing to find “Logged in as …”:
   - Ensure auto-start is NOT disabled for UI tests (only for Unit Tests).
   - Confirm the label text exactly matches, and wait up to ~12s for flow to complete.
   - If needed, adjust the scripted inputs or the expectation names (“Bob/Alice/Carol/Dana”) to match current fixtures.

3) Swift 6 actor error:
   - “Call to main actor-isolated initializer ‘init()’ …” likely means a call creating RealVoiceIO outside MainActor, or a default argument evaluated in a nonisolated context calling a @MainActor initializer.
   - Always create RealVoiceIO via await MainActor.run { RealVoiceIO() }.
   - If an ergonomic overload with default args triggers this, avoid default args or mark the wrapper @MainActor, or set context explicitly before calling listen.

Next high-level tasks
- Stabilize tests on macOS by ensuring all boosted waits are detached and time-bounded.
- Confirm RecognitionContext usage in login flows (names vs numbers).
- Extract VoiceIO into a Swift Package:
  - Public API marks on VoiceIO, RealVoiceIO, TTSConfigurable, RecognitionContext, VoiceResult.
  - Non-UI target at first (VoiceIO.swift + NameResolver.swift).
  - Optional UI target later (VoicePickerView.swift).

Formatting and delivery
- Return full file replacements when making complex changes.
- Use code blocks for every snippet.
- Keep kid-facing UI words simple; prefer “range” over “variation”.

Meta
- Be explicit when touching Swift 6 actor isolation.
- Avoid long-lived background work on the main actor; use detached tasks for waits.
- Always cancel TTS previews before starting a new one.
